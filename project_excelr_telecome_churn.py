# -*- coding: utf-8 -*-
"""Project Excelr Telecome churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k-zUHl2shc9RvaDePvpO_OATLl9jj-Kv

# Project Name : Telecome Churn

In the telecom industry, "churn" refers to the rate at which customers discontinue their services with a telecom operator. It is also called the "customer attrition rate". Essentially, it measures how many customers stop using a specific service within a certain period of time.


Churn is a critical metric for telecom companies as it indicates customer loyalty and satisfaction. High churn rates can negatively impact a company's profitability and growth by reducing their customer base. Understanding and reducing churn is key to ensuring long-term success.

1. Telecom churn means customers leaving a telecom service.
2. The churn rate is the percentage of customers who leave within a certain time.
3. It helps companies know if customers are happy or not happy with their service.
4. High churn is bad because it means the company is losing customers.

●	 21 columsns :

●	state: Categorical, for the 51 states and the District of Columbia.

●	Area.code

●	account.length: how long the account has Business Objective

●	been active.

●	voice.plan: yes or no, voicemail plan.

●	voice.messages: number of voicemail messages.

●	intl.plan: yes or no, international plan.

●	intl.mins: minutes customer used service to make international calls.

●	intl.calls: total number of international calls.

●	intl.charge: total international charge.

●	day.mins: minutes customer used service during the day.

●	day.calls: total number of calls during the day.

●	day.charge: total charge during the day.

●	eve.mins: minutes customer used service during the evening.

●	eve.calls: total number of calls during the evening.

●	eve.charge: total charge during the evening.

●	night.mins: minutes customer used service during the night.

●	night.calls: total number of calls during the night.

●	night.charge: total charge during the night.

●	customer.calls: number of calls to customer service.

●	churn: Categorical, yes or no. Indicator of whether the customer has left the company (yes or no).
"""

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/Telecome Churn/Churn.xlsx'

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
data = pd.read_excel(file_path)

data1 = data.copy()

# data1.info()
# RangeIndex: 5000 entries, 0 to 4999 (Rows)
# Data columns (total 21 columns):

data.head()

"""# EDA"""

### Step 1: Data Cleaning

# Step 1: Data Cleaning
# Drop irrelevant column
data = data.drop(columns=['Unnamed: 0'])

# Convert necessary columns to numeric
data['day.charge'] = pd.to_numeric(data['day.charge'], errors='coerce')
data['eve.mins'] = pd.to_numeric(data['eve.mins'], errors='coerce')

# errors = 'coerce' : This argument tells the function how to handle errors if it encounters values that cannot be converted to numbers.
# 'coerce' means it will replace any such values with NaN (Not a Number), which is a way to represent missing or invalid data in pandas.

# Check for missing values
missing_values = data.isnull().sum()

# data1.isnull().sum()
missing_values

data=data.dropna()

data.isnull().sum()

"""### Step 2: Data Overview"""

# Step 2: Data Overview
# Summary statistics
summary = data.describe()

summary

# Distribution of churn
churn_distribution = data['churn'].value_counts()

churn_distribution

"""### Step 3: Data Visualization"""

# Step 3: Data Visualization
# Correlation heatmap
plt.figure(figsize=(12, 8))

# Select only numerical features for correlation calculation
numerical_data = data.select_dtypes(include=['number'])
corr = numerical_data.corr()


sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

# Churn by state
plt.figure(figsize=(14, 6))
state_churn = data.groupby('state')['churn'].value_counts(normalize=True).unstack()

state_churn.plot(kind='bar', stacked=True, figsize=(14, 6), colormap='viridis')

plt.title('Churn Rate by State')
plt.xlabel('State')
plt.ylabel('Proportion')
plt.legend(title='Churn', loc='upper right')
plt.show()

# Boxplot: Day charge vs Churn
plt.figure(figsize=(8, 6))
sns.boxplot(x='churn', y='day.charge', data=data, palette='Set2')
plt.title('Day Charge vs Churn')
plt.show()

# Pair Plot
sns.pairplot(data[['day.mins', 'eve.mins', 'night.mins', 'churn']], hue='churn')
plt.show()

# Save cleaned data for future use
import os


# Define the directory and file path
cleaned_file_path = '/mnt/data/Cleaned_Churn.csv'
directory = os.path.dirname(cleaned_file_path)  # Extract the directory path

# Create the directory if it doesn't exist
if not os.path.exists(directory):
    os.makedirs(directory)

# Now save the data to the CSV file
data.to_csv(cleaned_file_path, index=False)

print("Data cleaning and EDA completed. Cleaned data saved to:", cleaned_file_path)



"""# Feature Engineering Section"""

# Feature Engineering Section
# Step 4: Feature Engineering
# Create new features
data['total.mins'] = data['day.mins'] + data['eve.mins'] + data['night.mins'] + data['intl.mins']
data['total.calls'] = data['day.calls'] + data['eve.calls'] + data['night.calls'] + data['intl.calls']
data['avg.charge.per.call'] = (data['day.charge'] + data['eve.charge'] + data['night.charge'] + data['intl.charge']) / data['total.calls']

data

"""### Encode categorical variables"""

# Encode categorical variables
data['voice.plan'] = data['voice.plan'].map({'yes': 1, 'no': 0})
data['intl.plan'] = data['intl.plan'].map({'yes': 1, 'no': 0})
data['churn'] = data['churn'].map({'yes': 1, 'no': 0})

data

# Save cleaned and engineered data for future use
engineered_file_path = '/mnt/data/Engineered_Churn.csv'
data.to_csv(engineered_file_path, index=False)

print("EDA completed. Feature Engineering completed. Data saved to:", engineered_file_path)



from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle

# Select only numerical features for scaling
numerical_features = data.select_dtypes(include=['number']).drop(columns=['churn'])

# Define features and target
X = numerical_features
y = data['churn']

"""### Split"""

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Model Building"""

# Model Building
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

"""# Model Evaluation"""

# Model Evaluation
y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print("Model Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", class_report)

"""# Feedback based on model performance"""

# Feedback based on model performance
if accuracy > 0.85:
    print("Great model performance! Consider fine-tuning hyperparameters for further improvement.")
elif accuracy > 0.75:
    print("Good performance, but there is room for improvement. Try feature selection or different algorithms.")
else:
    print("The model needs improvement. Consider engineering new features or using more complex models.")